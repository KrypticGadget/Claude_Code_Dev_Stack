name: Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.13'
  COVERAGE_THRESHOLD: 80

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Set test matrix
        id: set-matrix
        run: |
          echo "matrix=[
            {\"test-type\": \"python\", \"test-path\": \"tests/integration/python\"},
            {\"test-type\": \"typescript\", \"test-path\": \"tests/integration/typescript\"},
            {\"test-type\": \"e2e\", \"test-path\": \"tests/integration/e2e\"}
          ]" >> $GITHUB_OUTPUT

  python-tests:
    runs-on: ubuntu-latest
    needs: setup
    strategy:
      matrix:
        python-version: ['3.11', '3.12', '3.13']
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-xdist pytest-mock
          pip install aiohttp httpx pydantic
          pip install -r requirements.txt || echo "No requirements.txt found"
          
          # Install MCP generator dependencies
          cd core/generators/python/openapi_mcp_codegen
          pip install -e . || echo "No setup.py found, installing manually"
          pip install jinja2 pyyaml langchain-core || true
      
      - name: Lint Python code
        run: |
          pip install ruff black isort
          ruff check core/generators/python/ || true
          black --check core/generators/python/ || true
          isort --check-only core/generators/python/ || true
      
      - name: Run Python integration tests
        run: |
          cd tests/integration
          python -m pytest python/ \
            --cov=../../core/generators/python \
            --cov=../../core/semantic \
            --cov=../../core/lsp/hooks \
            --cov-report=xml:coverage-python.xml \
            --cov-report=html:coverage-python \
            --cov-report=term-missing \
            --cov-fail-under=${{ env.COVERAGE_THRESHOLD }} \
            --junit-xml=pytest-results.xml \
            -v --tb=short \
            --durations=10 \
            --maxfail=5
      
      - name: Upload Python test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: python-test-results-${{ matrix.python-version }}
          path: |
            tests/integration/pytest-results.xml
            tests/integration/coverage-python.xml
            tests/integration/coverage-python/
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: tests/integration/coverage-python.xml
          flags: python
          name: python-${{ matrix.python-version }}

  typescript-tests:
    runs-on: ubuntu-latest
    needs: setup
    strategy:
      matrix:
        node-version: ['18', '20', '22']
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          cd core/generators/nodejs && npm ci
          cd ../../../apps/web && npm ci
          cd ../backend && npm ci || echo "No backend package.json"
      
      - name: Lint TypeScript code
        run: |
          cd core/generators/nodejs
          npm run typecheck
          npm run format.check
      
      - name: Build TypeScript components
        run: |
          cd core/generators/nodejs
          npm run build
      
      - name: Run TypeScript integration tests
        run: |
          cd tests/integration
          npm test -- \
            --coverage \
            --coverageDirectory=coverage-typescript \
            --coverageReporters=lcov,html,text \
            --coverageThreshold='{"global":{"branches":${{ env.COVERAGE_THRESHOLD }},"functions":${{ env.COVERAGE_THRESHOLD }},"lines":${{ env.COVERAGE_THRESHOLD }},"statements":${{ env.COVERAGE_THRESHOLD }}}}' \
            --testResultsProcessor=jest-junit \
            --verbose \
            --detectOpenHandles \
            --forceExit
        env:
          JEST_JUNIT_OUTPUT_DIR: ./
          JEST_JUNIT_OUTPUT_NAME: jest-results.xml
      
      - name: Upload TypeScript test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: typescript-test-results-${{ matrix.node-version }}
          path: |
            tests/integration/jest-results.xml
            tests/integration/coverage-typescript/
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: tests/integration/coverage-typescript/lcov.info
          flags: typescript
          name: typescript-${{ matrix.node-version }}

  e2e-tests:
    runs-on: ubuntu-latest
    needs: [python-tests, typescript-tests]
    timeout-minutes: 30
    
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client
      
      - name: Install dependencies
        run: |
          npm ci
          cd core/generators/nodejs && npm ci && npm run build
          cd ../../../
          pip install -r requirements.txt || echo "No requirements.txt"
      
      - name: Start test services
        run: |
          # Start mock API server
          cd apps/backend && npm start &
          
          # Start semantic analysis service
          cd core/semantic && python -m uvicorn api.index:app --port 8080 &
          
          # Wait for services to start
          sleep 10
      
      - name: Run E2E tests
        run: |
          cd tests/integration
          npm run test:e2e -- \
            --coverage \
            --coverageDirectory=coverage-e2e \
            --testTimeout=60000 \
            --verbose
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results
          path: |
            tests/integration/coverage-e2e/
            tests/integration/e2e-results.xml

  performance-tests:
    runs-on: ubuntu-latest
    needs: [python-tests, typescript-tests]
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[performance]')
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          npm ci
          pip install pytest pytest-benchmark
      
      - name: Run performance tests
        run: |
          cd tests/integration
          pytest python/ -m performance --benchmark-json=benchmark-results.json
      
      - name: Upload performance results
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: tests/integration/benchmark-results.json

  security-tests:
    runs-on: ubuntu-latest
    needs: setup
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Snyk security scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
      
      - name: Run CodeQL analysis
        uses: github/codeql-action/init@v2
        with:
          languages: javascript, python
      
      - name: Perform CodeQL analysis
        uses: github/codeql-action/analyze@v2

  test-report:
    runs-on: ubuntu-latest
    needs: [python-tests, typescript-tests, e2e-tests]
    if: always()
    
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v3
      
      - name: Generate test report
        run: |
          echo "# Test Results Summary" > test-summary.md
          echo "" >> test-summary.md
          
          echo "## Coverage Summary" >> test-summary.md
          echo "- Target Coverage: ${{ env.COVERAGE_THRESHOLD }}%" >> test-summary.md
          
          if [ -f python-test-results-*/coverage-python.xml ]; then
            echo "- Python Coverage: ✅ Available" >> test-summary.md
          else
            echo "- Python Coverage: ❌ Missing" >> test-summary.md
          fi
          
          if [ -f typescript-test-results-*/coverage-typescript/lcov.info ]; then
            echo "- TypeScript Coverage: ✅ Available" >> test-summary.md
          else
            echo "- TypeScript Coverage: ❌ Missing" >> test-summary.md
          fi
          
          echo "" >> test-summary.md
          echo "## Test Results" >> test-summary.md
          
          # Count total tests
          TOTAL_TESTS=0
          PASSED_TESTS=0
          
          echo "- Total test suites: $(find . -name '*-results.xml' | wc -l)" >> test-summary.md
          echo "- Results available in artifacts" >> test-summary.md
          
          cat test-summary.md
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const testSummary = fs.readFileSync('test-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: testSummary
            });

  publish-results:
    runs-on: ubuntu-latest
    needs: [test-report]
    if: always() && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Download test results
        uses: actions/download-artifact@v3
      
      - name: Publish to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./coverage-html
          destination_dir: test-results/${{ github.run_number }}
      
      - name: Update latest results
        run: |
          echo "Latest test results: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/test-results/${{ github.run_number }}/" > latest-results.txt
      
      - name: Notify Slack on failure
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#ci-alerts'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          message: |
            Integration tests failed for ${{ github.repository }}
            Branch: ${{ github.ref_name }}
            Commit: ${{ github.sha }}
            Results: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}