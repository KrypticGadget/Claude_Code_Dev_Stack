[tool:pytest]
# pytest configuration file for hook testing framework

# Test discovery
testpaths = .
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Output and reporting
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --show-capture=no
    --durations=10
    --durations-min=1.0
    --maxfail=5
    --junit-xml=pytest_results.xml
    --html=pytest_report.html
    --self-contained-html
    --cov=../
    --cov-report=term-missing
    --cov-report=html:coverage_html
    --cov-report=xml:coverage.xml
    --cov-fail-under=75

# Test markers
markers =
    unit: Unit tests for individual components
    integration: Integration tests for component interactions
    performance: Performance and benchmark tests
    concurrency: Concurrency and thread safety tests
    regression: Regression tests for backward compatibility
    smoke: Smoke tests for basic functionality
    slow: Tests that take more than 30 seconds
    network: Tests that require network access
    external: Tests that depend on external services
    
# Timeout configuration
timeout = 300
timeout_method = thread

# Coverage configuration
cov-config = .coveragerc

# Warnings configuration
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning:distutils.*
    ignore::PendingDeprecationWarning
    ignore:.*:pytest.PytestUnraisableExceptionWarning

# Minimum version requirements
minversion = 6.0

# Test session configuration
console_output_style = progress
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Parallel execution
# Use with pytest-xdist: pytest -n auto
dist = loadfile
tx = 2*popen//python

# Custom collection rules
collect_ignore = [
    "setup.py",
    "ci/",
    "archive/",
    "temp/",
    "__pycache__"
]

# Performance test configuration
benchmark-min-rounds = 3
benchmark-max-time = 10
benchmark-min-time = 0.1
benchmark-warmup = true
benchmark-warmup-iterations = 2
benchmark-json = benchmark_results.json

# Hypothesis configuration (for property-based testing)
hypothesis-seed = 12345
hypothesis-max-examples = 100
hypothesis-deadline = 5000

# Asyncio configuration
asyncio_mode = auto

# Cache configuration
cache_dir = .pytest_cache

# Plugin configuration
xfail_strict = true